{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "\n",
    "# Setting frame Size\n",
    "cap.set(3,1366)\n",
    "cap.set(4,768)\n",
    "\n",
    "# Load our image template, this is our referece image\n",
    "image=cv2.imread('Image/test_image.png',0)\n",
    "\n",
    "while True:\n",
    "    \n",
    "    # Get webcam image\n",
    "    ret,frame=cap.read()\n",
    "    \n",
    "    # Get height and width of webcam frame\n",
    "    w,h = frame.shape[:2]\n",
    "    \n",
    "    # Define ROI dimensions\n",
    "    top_left_x = int(w/1.5)\n",
    "    top_left_y =int(3*(h/7))\n",
    "    bottom_right_x=int((w/1.8)*2)\n",
    "    bottom_right_y = int((h/3)-(h/5.5))\n",
    "    \n",
    "    # Draw Rectangle window for our region of interest\n",
    "    cv2.rectangle(frame,(top_left_x, top_left_y),(bottom_right_x , bottom_right_y),255,3)\n",
    "    \n",
    "    # Crop window of operation we defined above\n",
    "    cropped=frame[bottom_right_y:top_left_y,top_left_x:bottom_right_x]\n",
    "    \n",
    "    # Flip frame operation horizontally\n",
    "    frame=cv2.flip(frame,1)\n",
    "    \n",
    "    # Get number of orb matches\n",
    "    matches =orbDetector(cropped,image)\n",
    "    \n",
    "    # Display status string showing the number of correct matches\n",
    "    cv2.putText(frame,str(matches),(450,600),cv2.FONT_HERSHEY_COMPLEX,2,(0,255,0),1)\n",
    "    \n",
    "    # Our threshold to indicate object detection\n",
    "    threshold=350\n",
    "    \n",
    "    # If matches exceed our threshold then object is detected\n",
    "    if matches > threshold:\n",
    "        cv2.rectangle(frame,(top_left_x, top_left_y),(bottom_right_x , bottom_right_y),(0,255,0),3)\n",
    "        cv2.putText(frame,'object found',(450,150),cv2.FONT_HERSHEY_COMPLEX,2,(0,255,0),2)\n",
    "        \n",
    "        \n",
    "    cv2.imshow('fa',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def orbDetector(img,img_temp):\n",
    "    # Function that compares input image to template image\n",
    "    # It then returns number of ORB matches between them\n",
    "    \n",
    "    img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Create ORB detector with 1000 key points and with a scaling pyramid factor of 1.2\n",
    "    orb=cv2.ORB_create(1000, 1.2)\n",
    "    \n",
    "    # Detect key points of original image\n",
    "    (key1, des1)=orb.detectAndCompute(img, None)\n",
    "    \n",
    "    # Detect key points of template image\n",
    "    (key2, des2)=orb.detectAndCompute(img_temp,None)\n",
    "    \n",
    "    # Create matcher\n",
    "    bf=cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck= True)\n",
    "    \n",
    "    # Do matching\n",
    "    matches=bf.match(des1,des2)\n",
    "    \n",
    "    # Sort the matches based on distance\n",
    "    matches=sorted(matches, key=lambda x:x.distance)\n",
    "    \n",
    "    return len(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
